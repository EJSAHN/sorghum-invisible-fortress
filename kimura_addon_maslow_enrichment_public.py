#!/usr/bin/env python3
"""
kimura_addon_maslow_enrichment_public.py

Add-on to strengthen the "Maslow's Trap / quadrant" analysis so it is not just
a labeled scatter plot.

Reviewer-facing motivation:
- If you classify SNPs into quadrants by (beta_SDI, beta_disease), you should also
  quantify whether any quadrant is enriched among significant SNPs, and how results
  change with threshold choices (top 1% vs 5%, etc.), including allele frequency / effect
  size summaries.

Inputs expected (generated by kimura_pipeline_public.py):
- <out>/GWAS_SDI.csv
- <out>/GWAS_<disease_trait>.csv  (one or more)

Outputs written to <out>/addons_maslow/:
- maslow_enrichment_summary.csv
- maslow_allelefreq_effectsize_by_quadrant.csv
- plots/maslow_scatter_<trait>_top<xx>.pdf   (if --make_plots)

Notes:
- Works with standard OLS GWAS outputs. If you have LMM outputs, you can still
  feed them as long as they have chr,pos,beta,logp,maf columns.
"""

from __future__ import annotations

import argparse
import glob
import math
import os
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt


def bh_fdr(pvals: np.ndarray) -> np.ndarray:
    """
    Benjamini-Hochberg q-values for an array of p-values.
    """
    pvals = np.asarray(pvals, dtype=float)
    n = len(pvals)
    order = np.argsort(pvals)
    ranks = np.arange(1, n + 1, dtype=float)
    q = np.empty(n, dtype=float)
    q[order] = pvals[order] * n / ranks
    # enforce monotonicity
    q_sorted = q[order]
    q_sorted = np.minimum.accumulate(q_sorted[::-1])[::-1]
    q[order] = np.clip(q_sorted, 0.0, 1.0)
    return q


def classify_quadrant(beta_sdi: np.ndarray, beta_dis: np.ndarray) -> np.ndarray:
    """
    Quadrant labels:
      Qpp: +SDI, +Disease
      Qpn: +SDI, -Disease
      Qnp: -SDI, +Disease
      Qnn: -SDI, -Disease

    Also provides "Trap/FreeLunch/Fortress/Sacrifice" aliases for backwards compatibility.
    """
    beta_sdi = np.asarray(beta_sdi, dtype=float)
    beta_dis = np.asarray(beta_dis, dtype=float)
    out = np.empty(beta_sdi.shape[0], dtype=object)
    for i, (a, b) in enumerate(zip(beta_sdi, beta_dis)):
        if a >= 0 and b >= 0:
            out[i] = "Qpp"
        elif a >= 0 and b < 0:
            out[i] = "Qpn"
        elif a < 0 and b >= 0:
            out[i] = "Qnp"
        else:
            out[i] = "Qnn"
    return out


def quadrant_alias(q: str) -> str:
    # Match prior naming scheme used in drafts:
    # +SDI,+Disease = Trap
    # +SDI,-Disease = FreeLunch
    # -SDI,-Disease = Fortress
    # -SDI,+Disease = Sacrifice
    mapping = {
        "Qpp": "Trap",
        "Qpn": "FreeLunch",
        "Qnn": "Fortress",
        "Qnp": "Sacrifice",
    }
    return mapping.get(q, q)


def fisher_enrichment(sig_mask: np.ndarray, class_mask: np.ndarray) -> Tuple[float, float]:
    """
    Fisher's exact test for enrichment of a class among significant SNPs.

    Table:
      class & sig        a
      class & not sig    b
      not class & sig    c
      not class & not    d

    Returns odds_ratio, p_value
    """
    a = int(np.sum(class_mask & sig_mask))
    b = int(np.sum(class_mask & ~sig_mask))
    c = int(np.sum(~class_mask & sig_mask))
    d = int(np.sum(~class_mask & ~sig_mask))
    # avoid degenerate
    table = np.array([[a, b], [c, d]], dtype=int)
    try:
        odds, p = stats.fisher_exact(table, alternative="two-sided")
    except Exception:
        odds, p = float("nan"), float("nan")
    return float(odds), float(p)


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--out", type=str, default="outputs", help="Output folder from kimura_pipeline_public.py")
    ap.add_argument("--disease_pattern", type=str, default="GWAS_headsmut*.csv",
                    help="Glob pattern for disease GWAS files inside --out")
    ap.add_argument("--top_pcts", type=str, default="0.5,1,2,5",
                    help="Comma-separated top-percent thresholds by -log10(p) (e.g., '1,5')")
    ap.add_argument("--use_fdr", action="store_true",
                    help="Also compute BH-FDR q-values and report q<0.1 enrichment")
    ap.add_argument("--make_plots", action="store_true", help="Write PDF scatter plots")
    args = ap.parse_args()

    out_root = Path(args.out)
    gwas_sdi_path = out_root / "GWAS_SDI.csv"
    if not gwas_sdi_path.exists():
        raise FileNotFoundError(f"Missing {gwas_sdi_path}. Run kimura_pipeline_public.py first.")

    disease_files = sorted(glob.glob(str(out_root / args.disease_pattern)))
    if not disease_files:
        raise FileNotFoundError(f"No disease GWAS files matched pattern: {args.disease_pattern}")

    top_pcts = [float(x.strip()) for x in args.top_pcts.split(",") if x.strip()]
    top_pcts = sorted(set(top_pcts))

    addon_dir = out_root / "addons_maslow"
    plot_dir = addon_dir / "plots"
    addon_dir.mkdir(parents=True, exist_ok=True)
    plot_dir.mkdir(parents=True, exist_ok=True)

    gwas_sdi = pd.read_csv(gwas_sdi_path)
    required = {"chr", "pos", "beta", "logp"}
    if not required.issubset(set(gwas_sdi.columns)):
        raise ValueError(f"GWAS_SDI.csv missing required columns: {sorted(required - set(gwas_sdi.columns))}")

    # Normalize SDI GWAS column names
    gwas_sdi = gwas_sdi.rename(columns={"beta": "beta_sdi", "logp": "logp_sdi", "maf": "maf_sdi"})

    summary_rows: List[Dict] = []
    detail_rows: List[Dict] = []

    for f in disease_files:
        trait = Path(f).stem.replace("GWAS_", "")
        gwas_dis = pd.read_csv(f)

        if not required.issubset(set(gwas_dis.columns)):
            # skip files that aren't GWAS tables
            continue

        gwas_dis = gwas_dis.rename(columns={"beta": "beta_dis", "logp": "logp_dis", "maf": "maf_dis"})
        merged = pd.merge(gwas_sdi, gwas_dis, on=["chr", "pos"], how="inner", suffixes=("", ""))
        if merged.empty:
            continue

        # Use disease maf if present, else SDI maf
        if "maf_dis" in merged.columns:
            merged["maf"] = merged["maf_dis"]
        elif "maf_sdi" in merged.columns:
            merged["maf"] = merged["maf_sdi"]
        else:
            merged["maf"] = np.nan

        merged["quadrant"] = classify_quadrant(merged["beta_sdi"].to_numpy(), merged["beta_dis"].to_numpy())
        merged["quadrant_alias"] = merged["quadrant"].map(quadrant_alias)

        # Thresholds based on top percent of disease -log10(p)
        logp = merged["logp_dis"].to_numpy(dtype=float)
        for pct in top_pcts:
            q = 1.0 - pct / 100.0
            thr = float(np.nanquantile(logp, q))
            sig = logp >= thr

            # Overall chi-square across quadrants among sig vs all
            quads = ["Qpp", "Qpn", "Qnp", "Qnn"]
            obs = np.array([(merged["quadrant"] == qd).to_numpy() & sig for qd in quads]).sum(axis=1)
            exp = np.array([(merged["quadrant"] == qd).to_numpy() for qd in quads]).sum(axis=1)
            # Normalize exp to sig total
            exp = exp / exp.sum() * obs.sum() if exp.sum() > 0 else exp
            try:
                chi2, chi_p = stats.chisquare(f_obs=obs, f_exp=exp)
            except Exception:
                chi2, chi_p = float("nan"), float("nan")

            # Per-quadrant Fisher enrichments
            for qd in quads:
                class_mask = (merged["quadrant"] == qd).to_numpy()
                odds, p = fisher_enrichment(sig, class_mask)

                sub = merged.loc[class_mask & sig].copy()
                detail_rows.append({
                    "trait": trait,
                    "threshold_type": f"top{pct:.3g}pct_logp",
                    "logp_threshold": thr,
                    "quadrant": qd,
                    "quadrant_alias": quadrant_alias(qd),
                    "n_sig": int(sig.sum()),
                    "n_in_quadrant_sig": int(np.sum(class_mask & sig)),
                    "n_in_quadrant_total": int(np.sum(class_mask)),
                    "fisher_odds_ratio": odds,
                    "fisher_p": p,
                    "median_beta_sdi_sig": float(np.nanmedian(sub["beta_sdi"])) if len(sub) else float("nan"),
                    "median_beta_dis_sig": float(np.nanmedian(sub["beta_dis"])) if len(sub) else float("nan"),
                    "median_maf_sig": float(np.nanmedian(sub["maf"])) if len(sub) else float("nan"),
                })

            summary_rows.append({
                "trait": trait,
                "threshold_type": f"top{pct:.3g}pct_logp",
                "logp_threshold": thr,
                "n_total": int(len(merged)),
                "n_sig": int(sig.sum()),
                "chi2_quadrants": float(chi2),
                "chi2_p": float(chi_p),
                "counts_Qpp": int(np.sum((merged["quadrant"] == "Qpp") & sig)),
                "counts_Qpn": int(np.sum((merged["quadrant"] == "Qpn") & sig)),
                "counts_Qnp": int(np.sum((merged["quadrant"] == "Qnp") & sig)),
                "counts_Qnn": int(np.sum((merged["quadrant"] == "Qnn") & sig)),
            })

            if args.make_plots:
                fig = plt.figure()
                ax = fig.add_subplot(111)
                ax.scatter(merged["beta_sdi"], merged["beta_dis"], s=6, alpha=0.25)
                ax.scatter(merged.loc[sig, "beta_sdi"], merged.loc[sig, "beta_dis"], s=10)
                ax.axhline(0, linewidth=1)
                ax.axvline(0, linewidth=1)
                ax.set_xlabel("beta_SDI")
                ax.set_ylabel(f"beta_{trait}")
                ax.set_title(f"{trait}: beta_SDI vs beta_disease (top {pct:g}% by -log10(p))")
                fig.tight_layout()
                fig.savefig(plot_dir / f"maslow_scatter_{trait}_top{pct:g}pct.pdf")
                plt.close(fig)

        # Optional FDR-based enrichment
        if args.use_fdr:
            p_dis = 10 ** (-merged["logp_dis"].to_numpy(dtype=float))
            qvals = bh_fdr(p_dis)
            sig = qvals < 0.10
            quads = ["Qpp", "Qpn", "Qnp", "Qnn"]
            for qd in quads:
                class_mask = (merged["quadrant"] == qd).to_numpy()
                odds, p = fisher_enrichment(sig, class_mask)
                sub = merged.loc[class_mask & sig].copy()
                detail_rows.append({
                    "trait": trait,
                    "threshold_type": "fdr_q<0.10",
                    "logp_threshold": float("nan"),
                    "quadrant": qd,
                    "quadrant_alias": quadrant_alias(qd),
                    "n_sig": int(sig.sum()),
                    "n_in_quadrant_sig": int(np.sum(class_mask & sig)),
                    "n_in_quadrant_total": int(np.sum(class_mask)),
                    "fisher_odds_ratio": odds,
                    "fisher_p": p,
                    "median_beta_sdi_sig": float(np.nanmedian(sub["beta_sdi"])) if len(sub) else float("nan"),
                    "median_beta_dis_sig": float(np.nanmedian(sub["beta_dis"])) if len(sub) else float("nan"),
                    "median_maf_sig": float(np.nanmedian(sub["maf"])) if len(sub) else float("nan"),
                })

            summary_rows.append({
                "trait": trait,
                "threshold_type": "fdr_q<0.10",
                "logp_threshold": float("nan"),
                "n_total": int(len(merged)),
                "n_sig": int(sig.sum()),
                "chi2_quadrants": float("nan"),
                "chi2_p": float("nan"),
                "counts_Qpp": int(np.sum((merged["quadrant"] == "Qpp") & sig)),
                "counts_Qpn": int(np.sum((merged["quadrant"] == "Qpn") & sig)),
                "counts_Qnp": int(np.sum((merged["quadrant"] == "Qnp") & sig)),
                "counts_Qnn": int(np.sum((merged["quadrant"] == "Qnn") & sig)),
            })

    summary_df = pd.DataFrame(summary_rows)
    detail_df = pd.DataFrame(detail_rows)

    summary_df.to_csv(addon_dir / "maslow_enrichment_summary.csv", index=False)
    detail_df.to_csv(addon_dir / "maslow_allelefreq_effectsize_by_quadrant.csv", index=False)

    print(f"[OK] Wrote add-on outputs to: {addon_dir}")

if __name__ == "__main__":
    main()
